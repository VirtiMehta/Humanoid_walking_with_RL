{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "import nbimporter\n",
    "from simulation import Simulation\n",
    "\n",
    "class HumanoidEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom OpenAI Gym environment for controlling a humanoid's walk.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(HumanoidEnv, self).__init__()\n",
    "\n",
    "        # Initialize the simulation\n",
    "        self.simulation = Simulation()\n",
    "        self.simulation_clock = pygame.time.Clock()\n",
    "\n",
    "        # Define the action space: motor speeds for 4 joints\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-10, -10, -10, -10]),  # Min motor speeds\n",
    "            high=np.array([10, 10, 10, 10]),    # Max motor speeds\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Define the observation space based on the humanoid's log_state\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,  # Allow for unlimited observation values (customize if needed)\n",
    "            high=np.inf,\n",
    "            shape=(len(self.simulation.humanoid.log_state()),),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.previous_torso_x = 0  # Initialize previous torso x-position\n",
    "        del self.simulation\n",
    "        self.simulation = Simulation()\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Perform one step in the environment with the given action.\n",
    "\n",
    "        Args:\n",
    "            action (np.array): Motor speeds for the joints.\n",
    "\n",
    "        Returns:\n",
    "            observation (np.array): The new observation.\n",
    "            reward (float): The computed reward.\n",
    "            done (bool): Whether the episode is finished.\n",
    "            info (dict): Additional debug information.\n",
    "        \"\"\"\n",
    "        # Apply the action to the humanoid's motors\n",
    "        self.simulation.humanoid.update_motors(action)\n",
    "\n",
    "        # Step the simulation forward\n",
    "        self.simulation.world.Step(1.0 / 60.0, 6, 2)\n",
    "\n",
    "        # Get the new observation\n",
    "        observation = self._get_observation()\n",
    "\n",
    "        # Compute the reward\n",
    "        reward = self._compute_reward()\n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = self._is_done()\n",
    "\n",
    "        # Additional info (can include debug data if needed)\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, done,False, info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"\n",
    "        Render the environment using the simulation's rendering system.\n",
    "        \"\"\"\n",
    "        self.simulation.screen.fill(self.simulation.bg_color)\n",
    "        self.simulation.render_ground()\n",
    "        self.simulation.render_flag()\n",
    "        self.simulation.humanoid.render(self.simulation.screen, self.simulation.ppm)\n",
    "        pygame.display.flip()\n",
    "        self.simulation_clock.tick(60)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Close the environment.\n",
    "        \"\"\"\n",
    "        pygame.quit()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Get the current observation from the humanoid's state.\n",
    "\n",
    "        Returns:\n",
    "            np.array: The state as a flattened array.\n",
    "        \"\"\"\n",
    "        state = self.simulation.humanoid.log_state()\n",
    "        return np.array(list(state.values()), dtype=np.float32)\n",
    "\n",
    "    def _compute_reward(self):\n",
    "        \n",
    "        state = self.simulation.humanoid.log_state()\n",
    "\n",
    "        # Forward progress (reward forward motion, penalize backward motion)\n",
    "        forward_progress = max(0, state.get('torso_x', 0) - self.previous_torso_x)\n",
    "        backward_penalty = -10 if forward_progress < 0 else 0\n",
    "\n",
    "        # Balance maintenance (reward for maintaining torso height above threshold)\n",
    "        torso_height = state.get('torso_y', 0)\n",
    "        balance_reward = max(0, (torso_height - 1.0) * 10)\n",
    "\n",
    "        # Smooth movement (penalize large joint velocities)\n",
    "        joint_velocities = [state.get(f'joint_{i}_velocity', 0) for i in range(4)]\n",
    "        smoothness_penalty = -sum(abs(v) ** 2 for v in joint_velocities)\n",
    "\n",
    "        # Gait stability (encourage alternating leg movements)\n",
    "        leg_positions = [state.get(f'leg_{i}_position', 0) for i in range(2)]\n",
    "        gait_reward = 5 * abs(leg_positions[0] - leg_positions[1])\n",
    "\n",
    "        # Falling penalty\n",
    "        fall_penalty = -1000 if torso_height < 1.0 else 0\n",
    "\n",
    "        # Combine components\n",
    "        reward = forward_progress + backward_penalty + balance_reward + gait_reward + smoothness_penalty + fall_penalty\n",
    "\n",
    "        # Update internal state for next reward calculation\n",
    "        self.previous_torso_x = state.get('torso_x', 0)\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "    def _is_done(self):\n",
    "        state = self.simulation.humanoid.log_state()\n",
    "        x = state.get('torso_x', 0)\n",
    "        torso_height = state.get('torso_y', 0)\n",
    "\n",
    "        # End episode if humanoid falls or reaches goal\n",
    "        if torso_height < 1.0 or x > 16:\n",
    "            return True\n",
    "\n",
    "        return False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
